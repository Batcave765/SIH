{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "import requests\n",
    "import json\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "from flask import Flask, render_template\n",
    "import tempfile\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "import requests\n",
    "import json\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "import tempfile\n",
    "import re\n",
    "\n",
    "KEY = \"b2593d808fmsh9e1d03988d2fb89p1b007cjsn54cb0f23d804\"\n",
    "ENDPOINT = 'https://twitter135.p.rapidapi.com/Search/'\n",
    "HASHTAG = \"neersuraksha\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tensorflow in /home/sanjeevi/.local/lib/python3.10/site-packages (2.11.0)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from tensorflow) (59.6.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /home/sanjeevi/.local/lib/python3.10/site-packages (from tensorflow) (23.3.3)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/sanjeevi/.local/lib/python3.10/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/sanjeevi/.local/lib/python3.10/site-packages (from tensorflow) (1.4.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/sanjeevi/.local/lib/python3.10/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/sanjeevi/.local/lib/python3.10/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: packaging in /home/sanjeevi/.local/lib/python3.10/site-packages (from tensorflow) (23.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/sanjeevi/.local/lib/python3.10/site-packages (from tensorflow) (15.0.6.1)\n",
      "Requirement already satisfied: numpy>=1.20 in /home/sanjeevi/.local/lib/python3.10/site-packages (from tensorflow) (1.24.2)\n",
      "Requirement already satisfied: keras<2.12,>=2.11.0 in /home/sanjeevi/.local/lib/python3.10/site-packages (from tensorflow) (2.11.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /home/sanjeevi/.local/lib/python3.10/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/lib/python3/dist-packages (from tensorflow) (3.12.4)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/sanjeevi/.local/lib/python3.10/site-packages (from tensorflow) (4.8.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/sanjeevi/.local/lib/python3.10/site-packages (from tensorflow) (0.31.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/sanjeevi/.local/lib/python3.10/site-packages (from tensorflow) (3.8.0)\n",
      "Requirement already satisfied: tensorboard<2.12,>=2.11 in /home/sanjeevi/.local/lib/python3.10/site-packages (from tensorflow) (2.11.2)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/sanjeevi/.local/lib/python3.10/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/sanjeevi/.local/lib/python3.10/site-packages (from tensorflow) (2.2.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/sanjeevi/.local/lib/python3.10/site-packages (from tensorflow) (1.51.3)\n",
      "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /home/sanjeevi/.local/lib/python3.10/site-packages (from tensorflow) (2.11.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/lib/python3/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/sanjeevi/.local/lib/python3.10/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/sanjeevi/.local/lib/python3.10/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/sanjeevi/.local/lib/python3.10/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/sanjeevi/.local/lib/python3.10/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.16.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/sanjeevi/.local/lib/python3.10/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/sanjeevi/.local/lib/python3.10/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/sanjeevi/.local/lib/python3.10/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/sanjeevi/.local/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/sanjeevi/.local/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (4.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/sanjeevi/.local/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (5.3.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/sanjeevi/.local/lib/python3.10/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/sanjeevi/.local/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (3.2.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (1.26.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (2020.6.20)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/sanjeevi/.local/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow) (2.1.2)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/sanjeevi/.local/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/lib/python3/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow) (3.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-22 19:09:42.096722: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-22 19:09:42.401665: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-04-22 19:09:42.452962: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-04-22 19:09:42.452980: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-04-22 19:09:43.383258: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-04-22 19:09:43.383349: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-04-22 19:09:43.383356: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 940 images belonging to 5 classes.\n",
      "Found 940 images belonging to 5 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-22 19:09:44.295277: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2024-04-22 19:09:44.295587: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2024-04-22 19:09:44.295601: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (sanjeevi-ubuntu): /proc/driver/nvidia/version does not exist\n",
      "2024-04-22 19:09:44.296718: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 41\u001b[0m\n\u001b[1;32m     28\u001b[0m model \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mSequential([\n\u001b[1;32m     29\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mConv2D(\u001b[38;5;241m32\u001b[39m, (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m), activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m, input_shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m3\u001b[39m)),\n\u001b[1;32m     30\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mMaxPooling2D((\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m)),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     37\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(NUM_CLASSES, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     38\u001b[0m ])\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# Compile the model\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43madam\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m              \u001b[49m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcategorical_crossentropy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m              \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maccuracy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m     46\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(train_generator,\n\u001b[1;32m     47\u001b[0m           epochs\u001b[38;5;241m=\u001b[39mEPOCHS,\n\u001b[1;32m     48\u001b[0m           validation_data\u001b[38;5;241m=\u001b[39mvalid_generator)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/engine/training.py:740\u001b[0m, in \u001b[0;36mModel.compile\u001b[0;34m(self, optimizer, loss, metrics, loss_weights, weighted_metrics, run_eagerly, steps_per_execution, jit_compile, **kwargs)\u001b[0m\n\u001b[1;32m    738\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompiled_loss \u001b[38;5;241m=\u001b[39m loss\n\u001b[1;32m    739\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 740\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompiled_loss\u001b[49m \u001b[38;5;241m=\u001b[39m compile_utils\u001b[38;5;241m.\u001b[39mLossesContainer(\n\u001b[1;32m    741\u001b[0m         loss, loss_weights, output_names\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_names\n\u001b[1;32m    742\u001b[0m     )\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompiled_metrics \u001b[38;5;241m=\u001b[39m compile_utils\u001b[38;5;241m.\u001b[39mMetricsContainer(\n\u001b[1;32m    744\u001b[0m     metrics,\n\u001b[1;32m    745\u001b[0m     weighted_metrics,\n\u001b[1;32m    746\u001b[0m     output_names\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_names,\n\u001b[1;32m    747\u001b[0m     from_serialized\u001b[38;5;241m=\u001b[39mfrom_serialized,\n\u001b[1;32m    748\u001b[0m )\n\u001b[1;32m    750\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_configure_steps_per_execution(steps_per_execution \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/engine/training.py:361\u001b[0m, in \u001b[0;36mModel.__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[1;32m    355\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    356\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt looks like you are subclassing `Model` and you \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    357\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforgot to call `super().__init__()`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    358\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Always start with this line.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    359\u001b[0m         )\n\u001b[0;32m--> 361\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__setattr__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/engine/base_layer.py:3166\u001b[0m, in \u001b[0;36mLayer.__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   3161\u001b[0m             value\u001b[38;5;241m.\u001b[39m_use_resource_variables \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   3163\u001b[0m \u001b[38;5;66;03m# Append value to list of trainable / non-trainable weights if relevant\u001b[39;00m\n\u001b[1;32m   3164\u001b[0m \u001b[38;5;66;03m# TODO(b/125122625): This won't pick up on any variables added to a\u001b[39;00m\n\u001b[1;32m   3165\u001b[0m \u001b[38;5;66;03m# list/dict after creation.\u001b[39;00m\n\u001b[0;32m-> 3166\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_track_variables\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3168\u001b[0m \u001b[38;5;66;03m# TODO(b/180760306) Skip the auto trackable from tf.Module to keep\u001b[39;00m\n\u001b[1;32m   3169\u001b[0m \u001b[38;5;66;03m# status quo. See the comment at __delattr__.\u001b[39;00m\n\u001b[1;32m   3170\u001b[0m \u001b[38;5;28msuper\u001b[39m(tf\u001b[38;5;241m.\u001b[39m__internal__\u001b[38;5;241m.\u001b[39mtracking\u001b[38;5;241m.\u001b[39mAutoTrackable, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(\n\u001b[1;32m   3171\u001b[0m     name, value\n\u001b[1;32m   3172\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/engine/base_layer.py:3187\u001b[0m, in \u001b[0;36mLayer._track_variables\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   3185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(val, tf\u001b[38;5;241m.\u001b[39mVariable):\n\u001b[1;32m   3186\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_track_variable(val)\n\u001b[0;32m-> 3187\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[43mtf_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_extension_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   3188\u001b[0m     \u001b[38;5;66;03m# Manually expand extension types to track resource variables.\u001b[39;00m\n\u001b[1;32m   3189\u001b[0m     nested_vals \u001b[38;5;241m=\u001b[39m tf_utils\u001b[38;5;241m.\u001b[39mtype_spec_from_value(val)\u001b[38;5;241m.\u001b[39m_to_components(\n\u001b[1;32m   3190\u001b[0m         val\n\u001b[1;32m   3191\u001b[0m     )\n\u001b[1;32m   3192\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_track_variables(nested_vals)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/utils/tf_utils.py:384\u001b[0m, in \u001b[0;36mis_extension_type\u001b[0;34m(tensor)\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_extension_type\u001b[39m(tensor):\n\u001b[1;32m    371\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Returns whether a tensor is of an ExtensionType.\u001b[39;00m\n\u001b[1;32m    372\u001b[0m \n\u001b[1;32m    373\u001b[0m \u001b[38;5;124;03m    github.com/tensorflow/community/pull/269\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;124;03m      True if the tensor is an extension type object, false if not.\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 384\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__internal__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompositeTensor\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.10/abc.py:119\u001b[0m, in \u001b[0;36mABCMeta.__instancecheck__\u001b[0;34m(cls, instance)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__instancecheck__\u001b[39m(\u001b[38;5;28mcls\u001b[39m, instance):\n\u001b[1;32m    118\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Override for isinstance(instance, cls).\"\"\"\u001b[39;00m\n\u001b[0;32m--> 119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_abc_instancecheck\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minstance\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.10/abc.py:123\u001b[0m, in \u001b[0;36mABCMeta.__subclasscheck__\u001b[0;34m(cls, subclass)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__subclasscheck__\u001b[39m(\u001b[38;5;28mcls\u001b[39m, subclass):\n\u001b[1;32m    122\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Override for issubclass(subclass, cls).\"\"\"\u001b[39;00m\n\u001b[0;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_abc_subclasscheck\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubclass\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.10/abc.py:123\u001b[0m, in \u001b[0;36mABCMeta.__subclasscheck__\u001b[0;34m(cls, subclass)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__subclasscheck__\u001b[39m(\u001b[38;5;28mcls\u001b[39m, subclass):\n\u001b[1;32m    122\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Override for issubclass(subclass, cls).\"\"\"\u001b[39;00m\n\u001b[0;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_abc_subclasscheck\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubclass\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[0;31m[... skipping similar frames: ABCMeta.__subclasscheck__ at line 123 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m/usr/lib/python3.10/abc.py:123\u001b[0m, in \u001b[0;36mABCMeta.__subclasscheck__\u001b[0;34m(cls, subclass)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__subclasscheck__\u001b[39m(\u001b[38;5;28mcls\u001b[39m, subclass):\n\u001b[1;32m    122\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Override for issubclass(subclass, cls).\"\"\"\u001b[39;00m\n\u001b[0;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_abc_subclasscheck\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubclass\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.10/abc.py:121\u001b[0m, in \u001b[0;36mABCMeta.__subclasscheck__\u001b[0;34m(cls, subclass)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Override for isinstance(instance, cls).\"\"\"\u001b[39;00m\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _abc_instancecheck(\u001b[38;5;28mcls\u001b[39m, instance)\n\u001b[0;32m--> 121\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__subclasscheck__\u001b[39m(\u001b[38;5;28mcls\u001b[39m, subclass):\n\u001b[1;32m    122\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Override for issubclass(subclass, cls).\"\"\"\u001b[39;00m\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _abc_subclasscheck(\u001b[38;5;28mcls\u001b[39m, subclass)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Define constants\n",
    "IMAGE_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "NUM_CLASSES = 5\n",
    "EPOCHS = 10\n",
    "\n",
    "# Define data generators\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'Train',\n",
    "    target_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
    "valid_generator = valid_datagen.flow_from_directory(\n",
    "    'Validation',\n",
    "    target_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# Define model architecture\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_generator,\n",
    "          epochs=EPOCHS,\n",
    "          validation_data=valid_generator)\n",
    "\n",
    "# Save the model\n",
    "model.save('image_classification_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-22 19:49:50.070406: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-22 19:49:50.377988: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-04-22 19:49:50.429454: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-04-22 19:49:50.429473: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-04-22 19:49:51.424099: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-04-22 19:49:51.424173: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-04-22 19:49:51.424179: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Define your class labels based on your dataset\n",
    "class_labels = [\"earthquake\", \"flood\",\"landslide\",\"pipe_leakage\",\"tsunami\"]\n",
    "\n",
    "def classify_image(image_url):\n",
    "    # Load the saved model\n",
    "    model = tf.keras.models.load_model('image_classification_model.h5')\n",
    "    \n",
    "    # Download the image from the URL\n",
    "    response = requests.get(image_url)\n",
    "    img = Image.open(BytesIO(response.content))\n",
    "    \n",
    "    # Resize and preprocess the image\n",
    "    img = img.resize((224, 224))\n",
    "    img_array = np.array(img)\n",
    "    img_batch = np.expand_dims(img_array, axis=0)\n",
    "    img_preprocessed = img_batch / 255.0  # Normalize\n",
    "    \n",
    "    # Make predictions\n",
    "    predictions = model.predict(img_preprocessed)\n",
    "    \n",
    "    # Get the predicted class index\n",
    "    predicted_class_index = np.argmax(predictions)\n",
    "    \n",
    "    # Map the predicted class index to the class label\n",
    "    predicted_class_label = class_labels[predicted_class_index]\n",
    "    \n",
    "    return predicted_class_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "\n",
    "client = MongoClient(\"mongodb+srv://Mavericks:Mavericks123@cluster0.edxqwrh.mongodb.net/TweetDetails?retryWrites=true&w=majority\")\n",
    "db = client.TweetDetails\n",
    "collection = db.tweets_collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "\n",
    "def get_tweets_with_images_and_location():\n",
    "    request = requests.get(\n",
    "        ENDPOINT,\n",
    "        params={\n",
    "            \"q\": HASHTAG,\n",
    "            \"count\": 10,\n",
    "        },\n",
    "        headers={\n",
    "            \"x-rapidapi-key\": KEY,\n",
    "            \"x-rapidapi-host\": \"twitter135.p.rapidapi.com\",\n",
    "        },\n",
    "    )\n",
    "\n",
    "    tweets_with_location = []\n",
    "\n",
    "    if request.status_code == 200:\n",
    "        response_data = json.loads(request.text)\n",
    "        if \"data\" in response_data:\n",
    "            for entry in response_data[\"data\"]['search_by_raw_query']['search_timeline']['timeline']['instructions'][0]['entries']:\n",
    "                tweet_data = entry.get(\"content\", {}).get(\n",
    "                    \"itemContent\", {}).get(\"tweet_results\", {}).get(\"result\", {})\n",
    "                if tweet_data:\n",
    "                    image_media = tweet_data.get(\"legacy\", {}).get(\n",
    "                        \"entities\", {}).get(\"media\", [])\n",
    "                    if image_media:\n",
    "                        image_url = image_media[0].get(\"media_url_https\", \"\")\n",
    "                        # Check if the image URL is already present in MongoDB\n",
    "                        existing_tweet = collection.find_one({\"image_url\": image_url})\n",
    "                        if existing_tweet:\n",
    "                            # If image URL already exists, skip processing\n",
    "                            continue\n",
    "                        else:\n",
    "                            # If image URL doesn't exist, process it\n",
    "                            text = process_image_with_ocr(image_url)\n",
    "                            latitude, longitude = extract_location_from_text(text)\n",
    "                            classified_image = classify_image(image_url)\n",
    "                    else:\n",
    "                        image_url = \"\"\n",
    "                        latitude = None\n",
    "                        longitude = None\n",
    "                        classified_image = None\n",
    "                    tweet_text = tweet_data.get(\"full_text\", \"\")\n",
    "                    tweet_created_at = tweet_data.get(\"created_at\", \"\")\n",
    "                    if not tweet_text:\n",
    "                        tweet_text = f\"Tweet created at {tweet_created_at}\"\n",
    "                    tweets_with_location.append(\n",
    "                        {\"image_url\": image_url, \"tweet_text\": tweet_text, \"classified_image\": classified_image,\n",
    "                         \"latitude\": latitude, \"longitude\": longitude})\n",
    "        else:\n",
    "            return \"No tweet data found in the response.\"\n",
    "    else:\n",
    "        return f\"Request failed with status code {request.status_code}: {request.text}\"\n",
    "\n",
    "    return tweets_with_location\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image_with_ocr(image_url):\n",
    "    try:\n",
    "        response = requests.get(image_url)\n",
    "        if response.status_code == 200:\n",
    "            img = Image.open(BytesIO(response.content))\n",
    "            with tempfile.NamedTemporaryFile(delete=False, suffix='.png') as temp_image:\n",
    "                img.save(temp_image, format='PNG')\n",
    "            text = pytesseract.image_to_string(temp_image.name, lang='eng')\n",
    "            return text\n",
    "        else:\n",
    "            print(\n",
    "                f\"Image fetch failed with status code {response.status_code}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing image: {str(e)}\")\n",
    "    return \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_location_from_text(text):\n",
    "    latitude_pattern = r'Lat (\\d+\\.\\d+)°'\n",
    "    longitude_pattern = r'Long (\\d+\\.\\d+)°'\n",
    "\n",
    "    latitude_match = re.search(latitude_pattern, text)\n",
    "    longitude_match = re.search(longitude_pattern, text)\n",
    "\n",
    "    latitude = None\n",
    "    longitude = None\n",
    "\n",
    "    if latitude_match:\n",
    "        latitude = float(latitude_match.group(1))\n",
    "    if longitude_match:\n",
    "        longitude = float(longitude_match.group(1))\n",
    "\n",
    "    return latitude, longitude\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:5000\n",
      " * Running on http://192.168.212.161:5000\n",
      "Press CTRL+C to quit\n",
      "2024-04-22 19:50:29.122617: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2024-04-22 19:50:29.122937: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2024-04-22 19:50:29.122952: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (sanjeevi-ubuntu): /proc/driver/nvidia/version does not exist\n",
      "2024-04-22 19:50:29.124009: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 259ms/step\n",
      "[{'image_url': 'https://pbs.twimg.com/media/F6eoWODaIAEX4XK.jpg', 'tweet_text': 'Tweet created at ', 'classified_image': 'tsunami', 'latitude': 10.944494, 'longitude': 76.954094}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "192.168.212.161 - - [22/Apr/2024 19:50:33] \"GET / HTTP/1.1\" 200 -\n",
      "192.168.212.161 - - [22/Apr/2024 19:53:10] \"GET / HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, jsonify\n",
    "from flask_cors import CORS\n",
    "# from pymongo import MongoClient\n",
    "\n",
    "app = Flask(__name__)\n",
    "CORS(app)\n",
    "\n",
    "# MongoDB connection\n",
    "# client = MongoClient(\"mongodb+srv://Mavericks:Mavericks123@cluster0.edxqwrh.mongodb.net/TweetDetails?retryWrites=true&w=majority\")\n",
    "# db = client.TweetDetails\n",
    "# collection = db.tweets_collection\n",
    "\n",
    "# Modified index route to save tweets to MongoDB\n",
    "@app.route('/')\n",
    "def index():\n",
    "    # Retrieve tweets\n",
    "    tweets = get_tweets_with_images_and_location()\n",
    "    print(tweets)\n",
    "    # Save tweets to MongoDB\n",
    "    for tweet in tweets:\n",
    "        collection.insert_one(tweet)\n",
    "    \n",
    "    # Return response\n",
    "    return jsonify({\"message\": \"Tweets saved to MongoDB\"})\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
